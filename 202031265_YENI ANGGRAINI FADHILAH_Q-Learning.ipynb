{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skenario Robot di Dalam Gudang\n",
    "Perusahaan e-commerce yang berkembang sedang membangun gudang baru, dan perusahaan ingin semua operasi pengambilan di gudang baru dilakukan oleh robot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mendefinisikan Environment\n",
    "Environment terdiri dari states, actions, dan rewards. States dan actions adalah input untuk agen AI, sedangkan actions yang mungkin adalah output agen AI.\n",
    "\n",
    "#### States\n",
    "States di environment adalah semua kemungkinan lokasi di dalam gudang. Beberapa dari lokasi ini adalah untuk menyimpan barang (kotak hitam), sedangkan lokasi lainnya adalah lorong yang dapat digunakan robot untuk berjalan di seluruh gudang (kotak putih). Kotak hijau menunjukkan area pengemasan dan pengiriman barang.\n",
    "\n",
    "Kotak hitam dan hijau adalah terminal states!\n",
    "\n",
    "![QLearning1](QLearning1.png)\n",
    "\n",
    "Tujuan agen AI adalah mempelajari jalur terpendek antara area pengemasan barang dan semua lokasi lain di gudang tempat robot diizinkan untuk bepergian.\n",
    "\n",
    "Seperti yang ditunjukkan pada gambar di atas, ada 25 kemungkinan states (lokasi) di dalam gudang. States ini diatur dalam kisi yang berisi 5 baris dan 5 kolom. Setiap lokasi dapat diidentifikasi dengan indeks baris dan kolomnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "baris_environment=5\n",
    "kolom_environment=5\n",
    "\n",
    "nilai_nilai_q=np.zeros((baris_environment,kolom_environment, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actions\n",
    "Actions yang tersedia untuk agen AI adalah menggerakkan robot ke salah satu dari empat arah:\n",
    "* Atas\n",
    "* Kanan\n",
    "* Bawah\n",
    "* Kiri\n",
    "\n",
    "Agen AI harus belajar untuk menghindari mengemudi ke lokasi penyimpanan barang (misalnya rak)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions=['atas','kanan','bawah','kiri']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rewards\n",
    "Komponen terakhir dari environment yang perlu kita definisikan adalah **rewards**.\n",
    "\n",
    "Untuk membantu agen AI belajar, setiap states (lokasi) di gudang diberi nilai hadiah.\n",
    "\n",
    "Agen boleh mulai dari kotak putih mana saja, tetapi tujuannya selalu sama: ***untuk memaksimalkan total hadiah***!\n",
    "\n",
    "Imbalan negatif (yaitu, **hukuman**) digunakan untuk semua keadaan kecuali tujuan.\n",
    "Hal ini mendorong AI untuk mengidentifikasi *jalur terpendek* ke tujuan dengan *meminimalkan hukumannya*!\n",
    "\n",
    "![QLearning2](QLearning2.png)\n",
    "\n",
    "Untuk memaksimalkan hadiah kumulatifnya (dengan meminimalkan hukuman kumulatifnya), agen AI perlu menemukan jalur terpendek antara area pengemasan barang (kotak hijau) dan semua lokasi lain di gudang tempat robot diizinkan untuk bepergian (kotak putih ). Agen juga perlu belajar untuk menghindari menabrak salah satu lokasi penyimpanan item (kotak hitam)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-100. -100.  100. -100. -100.]\n",
      "[-1. -1. -1. -1. -1.]\n",
      "[  -1. -100. -100.   -1. -100.]\n",
      "[  -1.   -1.   -1.   -1. -100.]\n",
      "[-100.   -1. -100.   -1.   -1.]\n"
     ]
    }
   ],
   "source": [
    "rewards=np.full((baris_environment,kolom_environment), -100.)\n",
    "rewards[0,2]=100.\n",
    "\n",
    "lorong={}\n",
    "lorong[1]=[i for i in range(5)]\n",
    "lorong[2]=[0,3]\n",
    "lorong[3]=[i for i in range(4)]\n",
    "lorong[4]=[1,3,4]\n",
    "\n",
    "for baris_index in range(1,5):\n",
    "    for kolom_index in lorong[baris_index]:\n",
    "        rewards[baris_index, kolom_index]= -1.\n",
    "\n",
    "\n",
    "for baris in rewards:\n",
    "    print(baris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fungsi-fungsi Pembantu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fungsi untuk mengecek apakah kolom saat ini adalah terminal state\n",
    "def is_terminal_state(baris_index_saat_ini, kolom_index_saat_ini):\n",
    "    if rewards[baris_index_saat_ini, kolom_index_saat_ini] == -1.:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "# fungsi untuk memilih lokasi awal non-terminal secara acak\n",
    "def get_starting_location():\n",
    "    baris_index_saat_ini = np.random.randint(baris_environment)\n",
    "    kolom_index_saat_ini = np.random.randint(kolom_environment)\n",
    "    while is_terminal_state(baris_index_saat_ini, kolom_index_saat_ini):\n",
    "        baris_index_saat_ini = np.random.randint(baris_environment)\n",
    "        kolom_index_saat_ini = np.random.randint(kolom_environment)\n",
    "    return baris_index_saat_ini, kolom_index_saat_ini\n",
    "\n",
    "# fungsi untuk membuat sebuah algoritma epsilon greedy yang akan memilih tindakan mana yang akan diambil selanjutnya (ke mana agent harus pindah selanjutnya)\n",
    "def get_next_action(baris_index_saat_ini, kolom_index_saat_ini, epsilon):\n",
    "    if np.random.random() < epsilon:\n",
    "        return np.argmax(nilai_nilai_q[baris_index_saat_ini, kolom_index_saat_ini])\n",
    "    else:\n",
    "        return np.random.randint(4)\n",
    "\n",
    "# fungsi untuk mendapatkan lokasi berikutnya berdasarkan tindakan yang dipilih\n",
    "def get_next_location(baris_index_saat_ini, kolom_index_saat_ini, action_index):\n",
    "    baris_index_baru = baris_index_saat_ini\n",
    "    kolom_index_baru = kolom_index_saat_ini\n",
    "    if actions[action_index] == 'atas' and baris_index_saat_ini > 0:\n",
    "        baris_index_baru -= 1\n",
    "    elif actions[action_index] == 'kanan' and kolom_index_saat_ini < kolom_environment - 1:\n",
    "        kolom_index_baru += 1\n",
    "    elif actions[action_index] == 'bawah' and baris_index_saat_ini < baris_environment - 1:\n",
    "        baris_index_baru += 1\n",
    "    elif actions[action_index] == 'kiri' and kolom_index_saat_ini > 0:\n",
    "        kolom_index_baru -= 1\n",
    "    return baris_index_baru, kolom_index_baru\n",
    "\n",
    "# fungsi untuk mendapatkan jalur terpendek antara lokasi mana pun di dalam gudang\n",
    "def get_shortest_path(start_baris_index, start_kolom_index):\n",
    "    if is_terminal_state(start_baris_index, start_kolom_index):\n",
    "        return []\n",
    "    else:\n",
    "        baris_index_saat_ini, kolom_index_saat_ini = start_baris_index, start_kolom_index\n",
    "        jalur_terpendek = []\n",
    "        jalur_terpendek.append([baris_index_saat_ini, kolom_index_saat_ini])\n",
    "        while not is_terminal_state(baris_index_saat_ini, kolom_index_saat_ini):\n",
    "            action_index = get_next_action(baris_index_saat_ini, kolom_index_saat_ini, 1.)\n",
    "            baris_index_saat_ini, kolom_index_saat_ini = get_next_location(baris_index_saat_ini, kolom_index_saat_ini, action_index)\n",
    "            jalur_terpendek.append([baris_index_saat_ini, kolom_index_saat_ini])\n",
    "        return jalur_terpendek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Melatih AI Agent menggunakan Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Selesai\n"
     ]
    }
   ],
   "source": [
    "# training parameters\n",
    "epsilon = 0.9 # persentase waktu saat agan AI harus mengambil tindakan terbaik (bukan tindakan acak)\n",
    "discount_factor = 0.9 # untuk rewards di masa depan\n",
    "learning_rate = 0.9 # tingkat dimana agen AI harus belajar\n",
    "\n",
    "for episode in range(1000):\n",
    "    baris_index, kolom_index = get_starting_location()\n",
    "    while not is_terminal_state(baris_index, kolom_index):\n",
    "        action_index = get_next_action(baris_index, kolom_index, epsilon)\n",
    "        \n",
    "        baris_index_lama, kolom_index_lama = baris_index, kolom_index\n",
    "        baris_index, kolom_index = get_next_location(baris_index, kolom_index, action_index)\n",
    "        \n",
    "        reward = rewards[baris_index, kolom_index]\n",
    "        nilai_q_lama = nilai_nilai_q[baris_index_lama, kolom_index_lama, action_index]\n",
    "        perbedaan_temporal = reward + (discount_factor + np.max(nilai_nilai_q[baris_index, kolom_index])) - nilai_q_lama\n",
    "        \n",
    "        nilai_q_baru = nilai_q_lama + (learning_rate * perbedaan_temporal)\n",
    "        nilai_nilai_q[baris_index_lama, kolom_index_lama, action_index] = nilai_q_baru\n",
    "        \n",
    "print('Training Selesai')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mendapatkan Jalur Terpendek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4, 4], [4, 3], [3, 3], [2, 3], [1, 3], [1, 2], [0, 2]]\n"
     ]
    }
   ],
   "source": [
    "print(get_shortest_path(4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4, 1], [3, 1], [3, 0], [2, 0], [1, 0], [1, 1], [1, 2], [0, 2]]\n"
     ]
    }
   ],
   "source": [
    "print(get_shortest_path(4,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skenario yang Berlawanan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 2], [1, 2], [1, 1], [1, 0], [2, 0], [3, 0]]\n"
     ]
    }
   ],
   "source": [
    "path = get_shortest_path(3,0)\n",
    "path.reverse()\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
